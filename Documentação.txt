üìò PBPM AI Gateway - Documenta√ß√£o Oficial

Vis√£o Geral

Esta API atua como um Gateway Inteligente e Firewall para infraestrutura de LLMs locais (Ollama). Ela adiciona camadas de seguran√ßa, auditoria e gerenciamento avan√ßado de mem√≥ria VRAM, permitindo a execu√ß√£o eficiente de m√∫ltiplos modelos em hardware limitado.

Principais Funcionalidades:

Autentica√ß√£o: Segrega√ß√£o entre Admin (Cria√ß√£o de chaves) e Clientes (Infer√™ncia).

Gest√£o de VRAM: Mant√©m modelos leves sempre ativos e alterna modelos pesados sob demanda ("Heavy Swap").

Auditoria: Registro de tokens consumidos e data/hora por chave de cliente.

Auto-Discovery: Detec√ß√£o autom√°tica de modelos instalados no Ollama.

üîê Autentica√ß√£o

A API utiliza autentica√ß√£o via Bearer Token no Header das requisi√ß√µes. Existem dois tipos de chaves com permiss√µes distintas:

Tipo de Chave

Prefixo

Permiss√µes

Restri√ß√µes

Mestra (Admin)

(Definida no .env)

Criar novas chaves de cliente.

N√ÉO pode realizar infer√™ncia (chat/generate).

Cliente (User)

pbpm-...

Realizar infer√™ncia, listar modelos, preload.

N√£o pode criar novas chaves.

Exemplo de Header:

Authorization: Bearer pbpm-seu-token-aqui


üõ†Ô∏è Endpoints Administrativos

Requer: Chave Mestra

1. Criar Nova Chave (POST /admin/create_key)

Gera uma nova credencial de acesso para uma aplica√ß√£o ou usu√°rio. O email pode ser repetido para gerar m√∫ltiplas chaves para o mesmo dono.

Body (JSON):

{
  "name": "Nome da Aplica√ß√£o",
  "email": "contato@dominio.com"
}


Resposta (200 OK):

{
  "message": "Criado",
  "api_key": "pbpm-8f7d6a...", 
  "registered_to": {
    "name": "Nome da Aplica√ß√£o",
    "email": "contato@dominio.com"
  }
}


‚öôÔ∏è Endpoints de Sistema e Utilit√°rios

Requer: Chave de Cliente

2. Listar Modelos (GET /api/available_models)

Retorna o cat√°logo de modelos dispon√≠veis e seu status de mem√≥ria.

Resposta (200 OK):

{
  "models": [
    {
      "name": "llama3.2:3b",
      "size": 2000000000,
      "type": "always_on" 
    },
    {
      "name": "qwen2.5:32b",
      "size": 19000000000,
      "type": "on_demand"
    }
  ]
}


always_on: Modelos leves que est√£o sempre carregados na RAM/VRAM (Resposta instant√¢nea).

on_demand: Modelos pesados que requerem carregamento pr√©vio.

3. Preload / Aquecimento (POST /preload)

Instrui a API a carregar um modelo pesado na mem√≥ria antes da infer√™ncia.
Isso aciona o sistema de "Heavy Swap", descarregando outros modelos pesados para liberar espa√ßo.

Body (JSON):

{
  "model": "qwen2.5:32b"
}


Resposta (200 OK):

{
  "status": "ready",
  "model": "qwen2.5:32b"
}


üí¨ Endpoints de Infer√™ncia (Ollama Proxy)

Requer: Chave de Cliente

A API repassa as requisi√ß√µes para o Ollama, mas antes executa:

Valida√ß√£o da Chave.

Verifica√ß√£o de mem√≥ria (se o modelo n√£o estiver carregado, ele carrega automaticamente, o que pode adicionar delay).

Contagem de Tokens na resposta.

4. Chat Completion (POST /api/chat)

Compat√≠vel com a API de Chat do Ollama/OpenAI.

Body (JSON):

{
  "model": "llama3.2:3b",
  "messages": [
    { "role": "user", "content": "Ol√°, analise este documento..." }
  ],
  "stream": true
}


5. Generate (POST /api/generate)

Para completa√ß√£o de texto simples (Raw completion).

Body (JSON):

{
  "model": "codestral:latest",
  "prompt": "def hello_world():",
  "stream": false
}


üß† Comportamento de Mem√≥ria (Smart VRAM)

Para respeitar o limite de mem√≥ria (ex: 26GB) do container, a API segue regras estritas:

Zona Segura (Always On): Modelos definidos no .env (ex: llama3.2:3b) nunca s√£o descarregados. Eles residem permanentemente na mem√≥ria para respostas r√°pidas.

Zona Exclusiva (Heavy Swap): Apenas UM modelo pesado (n√£o listado no .env) pode rodar por vez.

Se codestral est√° rodando e voc√™ pede qwen2.5, a API derruba o codestral imediatamente e sobe o qwen2.5.

Recomenda√ß√£o: Use o endpoint /preload 5-10 segundos antes de precisar de um modelo pesado para evitar timeouts na chamada de infer√™ncia.

üö¶ C√≥digos de Erro Comuns

C√≥digo

Significado

Causa Prov√°vel

401

Unauthorized

Chave de API inv√°lida ou ausente.

403

Forbidden

Tentativa de usar Chave Mestra para endpoint de Chat/Preload.

500

Internal Error

Erro de conex√£o com container Ollama ou falha no Banco de Dados.

400

Bad Request

JSON mal formatado ou campos obrigat√≥rios faltando.

üêç Exemplo de Uso (Python)

import requests

API_URL = "[https://ia.pbpmdev.com](https://ia.pbpmdev.com)"
API_KEY = "pbpm-sua-chave-cliente-aqui"

headers = {"Authorization": f"Bearer {API_KEY}"}

# 1. (Opcional) Preload de modelo pesado
requests.post(f"{API_URL}/preload", json={"model": "codestral:latest"}, headers=headers)

# 2. Chamada de Chat
payload = {
    "model": "codestral:latest",
    "messages": [{"role": "user", "content": "Crie uma fun√ß√£o fibonacci em Python"}],
    "stream": False
}

response = requests.post(f"{API_URL}/api/chat", json=payload, headers=headers)
print(response.json()['message']['content'])
